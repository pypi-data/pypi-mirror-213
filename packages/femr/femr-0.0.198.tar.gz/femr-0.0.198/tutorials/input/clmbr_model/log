2023-05-30 15:09:04,484 [MainThread  ] [INFO ]  Training model with Namespace(directory='trash/tutorial_5/clmbr_model', data_path='input/extract', batches_path='trash/tutorial_5/clmbr_batches', learning_rate=0.0001, rotary_type='per_head', clmbr_survival_dim=None, num_batch_threads=3, start_from_checkpoint=None, freeze_weights=False, token_dropout=0, internal_dropout=0, weight_decay=0, max_iter=10, hidden_size=256, intermediate_size=256, n_heads=4, n_layers=1, attention_width=512, dev_batches_path=None, linear_probe_head=None, early_stopping_window_steps=None)
2023-05-30 15:09:04,496 [MainThread  ] [INFO ]  Got config {'data_path': 'input/extract', 'batch_info_path': 'trash/tutorial_5/clmbr_batches/batch_info.msgpack', 'seed': 97, 'task': {'type': 'clmbr', 'vocab_size': 8192}, 'transformer': {'vocab_size': 2048, 'hidden_size': 256, 'intermediate_size': 256, 'n_heads': 4, 'n_layers': 1, 'rotary': 'per_head', 'attention_width': 496, 'internal_dropout': 0, 'is_hierarchical': False, 'note_embedding_data': None}, 'learning_rate': 0.0001, 'max_grad_norm': 1.0, 'weight_decay': 0, 'n_epochs': 100}
2023-05-30 15:09:04,686 [MainThread  ] [INFO ]  Loaded batches 1 1
2023-05-30 15:09:06,475 [MainThread  ] [INFO ]  Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
2023-05-30 15:09:06,475 [MainThread  ] [INFO ]  Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
2023-05-30 15:09:06,475 [MainThread  ] [INFO ]  Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
2023-05-30 15:09:13,131 [MainThread  ] [INFO ]  Got dummy batch {'num_indices': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'num_patients': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'offsets': ((512,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'patient_ids': ((512,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'task': {'labels': ((4096,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0))}, 'transformer': {'ages': ((16384,), dtype('float32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'label_indices': ((4096,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'length': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'normalized_ages': ((16384,), dtype('float32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'tokens': ((16384,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'valid_tokens': ((16384,), dtype('bool'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0))}}
2023-05-30 15:09:13,234 [MainThread  ] [INFO ]  Transformed the model function
2023-05-30 15:09:14,364 [MainThread  ] [INFO ]  Done initing {'EHRTransformer/~/CLMBRTask/~/linear': {'b': ((8192,), dtype('float32')), 'w': ((256, 8192), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/embed': {'embeddings': ((2048, 256), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear': {'b': ((1024,), dtype('float32')), 'w': ((256, 1024), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear_1': {'b': ((256,), dtype('float32')), 'w': ((512, 256), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/rms_norm': {'scale': ((256,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm': {'scale': ((256,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm_1': {'scale': ((256,), dtype('float32'))}}
2023-05-30 15:09:14,364 [MainThread  ] [INFO ]  Total params 3024896
2023-05-30 15:09:14,365 [MainThread  ] [INFO ]  total steps 100 num train batches 1
2023-05-30 15:09:14,365 [MainThread  ] [INFO ]  Applying decay mask {'EHRTransformer/~/CLMBRTask/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/embed': {'embeddings': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm_1': {'scale': False}}
2023-05-30 15:09:14,365 [MainThread  ] [INFO ]  Using weight decay 0
2023-05-30 15:09:14,977 [MainThread  ] [INFO ]  Starting loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=array(0, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:17,229 [MainThread  ] [INFO ]  Starting train loss {'loss': 9.364985466003418, 'c_statistic': -9.364985466003418}
2023-05-30 15:09:17,879 [MainThread  ] [INFO ]  Starting dev loss {'loss': 9.403003692626953, 'c_statistic': -9.403003692626953}
2023-05-30 15:09:18,595 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=array(0, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:18,615 [MainThread  ] [INFO ]  Train loss {'loss': 9.364985466003418, 'c_statistic': -9.364985466003418}
2023-05-30 15:09:18,625 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403003692626953, 'c_statistic': -9.403003692626953}
2023-05-30 15:09:18,768 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,375 [MainThread  ] [INFO ]  [Step 0]
2023-05-30 15:09:21,391 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(2, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,629 [MainThread  ] [INFO ]  Train loss {'loss': 9.365042686462402, 'c_statistic': -9.365042686462402}
2023-05-30 15:09:21,637 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403146743774414, 'c_statistic': -9.403146743774414}
2023-05-30 15:09:21,638 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,641 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(3, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,657 [MainThread  ] [INFO ]  Train loss {'loss': 9.365055084228516, 'c_statistic': -9.365055084228516}
2023-05-30 15:09:21,666 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403162956237793, 'c_statistic': -9.403162956237793}
2023-05-30 15:09:21,667 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,672 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(4, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,688 [MainThread  ] [INFO ]  Train loss {'loss': 9.365017890930176, 'c_statistic': -9.365017890930176}
2023-05-30 15:09:21,697 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403162956237793, 'c_statistic': -9.403162956237793}
2023-05-30 15:09:21,697 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,700 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(5, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,715 [MainThread  ] [INFO ]  Train loss {'loss': 9.364958763122559, 'c_statistic': -9.364958763122559}
2023-05-30 15:09:21,720 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403115272521973, 'c_statistic': -9.403115272521973}
2023-05-30 15:09:21,720 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,723 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(6, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,738 [MainThread  ] [INFO ]  Train loss {'loss': 9.36495304107666, 'c_statistic': -9.36495304107666}
2023-05-30 15:09:21,744 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403003692626953, 'c_statistic': -9.403003692626953}
2023-05-30 15:09:21,744 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,747 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(7, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,763 [MainThread  ] [INFO ]  Train loss {'loss': 9.3649263381958, 'c_statistic': -9.3649263381958}
2023-05-30 15:09:21,768 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403178215026855, 'c_statistic': -9.403178215026855}
2023-05-30 15:09:21,769 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,771 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(8, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,787 [MainThread  ] [INFO ]  Train loss {'loss': 9.364903450012207, 'c_statistic': -9.364903450012207}
2023-05-30 15:09:21,792 [MainThread  ] [INFO ]  Dev loss {'loss': 9.40305233001709, 'c_statistic': -9.40305233001709}
2023-05-30 15:09:21,793 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,795 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(9, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,811 [MainThread  ] [INFO ]  Train loss {'loss': 9.364849090576172, 'c_statistic': -9.364849090576172}
2023-05-30 15:09:21,816 [MainThread  ] [INFO ]  Dev loss {'loss': 9.40294075012207, 'c_statistic': -9.40294075012207}
2023-05-30 15:09:21,845 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,849 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(10, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,865 [MainThread  ] [INFO ]  Train loss {'loss': 9.364794731140137, 'c_statistic': -9.364794731140137}
2023-05-30 15:09:21,870 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403194427490234, 'c_statistic': -9.403194427490234}
2023-05-30 15:09:21,870 [MainThread  ] [INFO ]  Continuing to train ...
2023-05-30 15:09:21,873 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(11, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))
2023-05-30 15:09:21,889 [MainThread  ] [INFO ]  Train loss {'loss': 9.364797592163086, 'c_statistic': -9.364797592163086}
2023-05-30 15:09:21,894 [MainThread  ] [INFO ]  Dev loss {'loss': 9.403162956237793, 'c_statistic': -9.403162956237793}
2023-05-30 15:09:21,895 [MainThread  ] [INFO ]  Stopping due to max iter
