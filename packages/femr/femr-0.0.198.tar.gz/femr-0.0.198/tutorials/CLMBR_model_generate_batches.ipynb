{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25c86161-50c4-4c92-bf30-3c588bb8c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This script walks through the various steps to train and use CLMBR.\n",
    "\n",
    "    In order to use this script, the assumption is that you already have a set of labels and an extract\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "#EXTRACT_LOCATION = \"/local-scratch/nigam/projects/ethanid/shared_tutorial_files/piton_new3_extract\"\n",
    "EXTRACT_LOCATION = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2\"\n",
    "LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to12m/labeled_patients.pkl\"\n",
    "TEMP_STORAGE = \"trash/clmbr_data\"\n",
    "\n",
    "os.makedirs(TEMP_STORAGE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594b02d4-0f6d-4834-bfe5-de1104be8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c86bc8bd-c83f-4c39-b398-9c808aeff391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The first step of training CLMBR is creating a dictionary, that helps map codes to integers that can be used within a neural network.\n",
    "\"\"\"\n",
    "\n",
    "DICTIONARY_PATH = os.path.join(TEMP_STORAGE, \"dictionary\")\n",
    "\n",
    "if not os.path.exists(DICTIONARY_PATH):\n",
    "    assert 0 == os.system(f\"clmbr_create_dictionary {DICTIONARY_PATH} --data_path {EXTRACT_LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65c02381-73c8-4fa9-a38c-c48db1f94352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:19:26,291 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='trash/clmbr_data/clmbr_batches', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='trash/clmbr_data/dictionary', task='clmbr', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path=None, is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 07:20:11,831 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 07:20:11,831 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0 out of 655360 out of 65536\n",
      "\n",
      "\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0When mapping codes, dropped When mapping codes, dropped 00When mapping codes, dropped  out of \n",
      "65536 out of \n",
      "65536\n",
      "When mapping codes, dropped When mapping codes, dropped 0 out of 65536\n",
      " out of 65536\n",
      "0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of When mapping codes, dropped 0 out of 655360 out of 65536\n",
      "65536\n",
      "\n",
      " out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped When mapping codes, dropped When mapping codes, dropped 00 out of When mapping codes, dropped 6553600 out of  out of 65536 out of When mapping codes, dropped \n",
      "0\n",
      "6553665536 out of 65536\n",
      "\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:22:14,257 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:23:21,919 [MainThread  ] [INFO ]  Number of train patients 98177\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The second step of training CLMBR is to prepare the batches that will actually get fed into the neural network.\n",
    "\"\"\"\n",
    "\n",
    "CLMBR_BATCHES = os.path.join(TEMP_STORAGE, \"clmbr_batches\")\n",
    "\n",
    "if not os.path.exists(CLMBR_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {CLMBR_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task clmbr\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214ab237-5967-4173-9833-3f7f71fe9ebe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:23:26,982 [MainThread  ] [INFO ]  Training model with Namespace(directory='trash/clmbr_data/clmbr_model', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', batches_path='trash/clmbr_data/clmbr_batches', learning_rate=0.0001, rotary_type='per_head', clmbr_survival_dim=None, num_batch_threads=3, start_from_checkpoint=None, freeze_weights=False, token_dropout=0, internal_dropout=0, weight_decay=0, max_iter=1000, hidden_size=768, intermediate_size=3072, n_heads=12, n_layers=6, attention_width=512, early_stopping_window_steps=None)\n",
      "2023-05-21 07:23:42,942 [MainThread  ] [INFO ]  Got config {'data_path': '/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', 'batch_info_path': 'trash/clmbr_data/clmbr_batches/batch_info.msgpack', 'seed': 97, 'task': {'type': 'clmbr', 'vocab_size': 8192}, 'transformer': {'vocab_size': 65536, 'hidden_size': 768, 'intermediate_size': 3072, 'n_heads': 12, 'n_layers': 6, 'rotary': 'per_head', 'attention_width': 496, 'internal_dropout': 0, 'is_hierarchical': False, 'note_embedding_data': None}, 'learning_rate': 0.0001, 'max_grad_norm': 1.0, 'weight_decay': 0, 'n_epochs': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:24:50,706 [MainThread  ] [INFO ]  Loaded batches 98177 6048\n",
      "2023-05-21 07:24:52,349 [MainThread  ] [INFO ]  Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA Interpreter Host\n",
      "2023-05-21 07:24:52,349 [MainThread  ] [INFO ]  Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
      "2023-05-21 07:24:52,350 [MainThread  ] [INFO ]  Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "2023-05-21 07:24:53,340 [MainThread  ] [INFO ]  Got dummy batch {'num_indices': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'num_patients': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'offsets': ((512,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'patient_ids': ((512,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'task': {'labels': ((16384,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0))}, 'transformer': {'ages': ((16384,), dtype('float32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'label_indices': ((16384,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'length': ((), dtype('int32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'normalized_ages': ((16384,), dtype('float32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'tokens': ((16384,), dtype('uint32'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)), 'valid_tokens': ((16384,), dtype('bool'), StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0))}}\n",
      "2023-05-21 07:24:53,781 [MainThread  ] [INFO ]  Transformed the model function\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the transformer ... (16384,) (16384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:24:55,857 [MainThread  ] [INFO ]  Done initing {'EHRTransformer/~/CLMBRTask/~/linear': {'b': ((8192,), dtype('float32')), 'w': ((768, 8192), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/embed': {'embeddings': ((65536, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/linear': {'b': ((5376,), dtype('float32')), 'w': ((768, 5376), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/linear_1': {'b': ((768,), dtype('float32')), 'w': ((3840, 768), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm': {'scale': ((768,), dtype('float32'))}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm_1': {'scale': ((768,), dtype('float32'))}}\n",
      "2023-05-21 07:24:55,857 [MainThread  ] [INFO ]  Total params 99141632\n",
      "2023-05-21 07:24:55,858 [MainThread  ] [INFO ]  total steps 9817700 num train batches 98177\n",
      "2023-05-21 07:24:55,858 [MainThread  ] [INFO ]  Applying decay mask {'EHRTransformer/~/CLMBRTask/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/embed': {'embeddings': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_0/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_1/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_2/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_3/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_4/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/linear': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/linear_1': {'b': False, 'w': True}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/loop_5/TransformerBlock/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm': {'scale': False}, 'EHRTransformer/~/TransformerFeaturizer/~/Transformer/~/rms_norm_1': {'scale': False}}\n",
      "2023-05-21 07:24:55,858 [MainThread  ] [INFO ]  Using weight decay 0\n",
      "2023-05-21 07:24:56,665 [MainThread  ] [INFO ]  Starting loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=array(0, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the transformer ... (16384,) (16384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:25:02,161 [MainThread  ] [INFO ]  Starting train loss {'loss': 9.388360977172852, 'c_statistic': -9.388360977172852}\n",
      "2023-05-21 07:25:05,119 [MainThread  ] [INFO ]  Starting dev loss {'loss': 9.388991355895996, 'c_statistic': -9.388991355895996}\n",
      "Working with seed 9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "Compiling the transformer ... (16384,) (16384,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zphuo/miniconda3/envs/FEMR_ENV/lib/python3.10/site-packages/jax/_src/interpreters/mlir.py:711: UserWarning: Some donated buffers were not usable: ShapedArray(uint32[16384]), ShapedArray(float32[16384]), ShapedArray(uint32[16384]), ShapedArray(int32[], weak_type=True), ShapedArray(uint32[16384]), ShapedArray(bool[16384]).\n",
      "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
      "  warnings.warn(f\"Some donated buffers were not usable: {', '.join(unused_donations)}.\\n{msg}\")\n",
      "2023-05-21 07:29:54,264 [MainThread  ] [INFO ]  [Step 0]\n",
      "2023-05-21 07:30:13,175 [MainThread  ] [INFO ]  [Step 100]\n",
      "2023-05-21 07:30:32,224 [MainThread  ] [INFO ]  [Step 200]\n",
      "2023-05-21 07:30:51,322 [MainThread  ] [INFO ]  [Step 300]\n",
      "2023-05-21 07:31:10,461 [MainThread  ] [INFO ]  [Step 400]\n",
      "2023-05-21 07:31:29,755 [MainThread  ] [INFO ]  [Step 500]\n",
      "2023-05-21 07:31:29,756 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(500, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))\n",
      "2023-05-21 07:31:34,363 [MainThread  ] [INFO ]  Train loss {'loss': 8.959304809570312, 'c_statistic': -8.959304809570312}\n",
      "2023-05-21 07:31:37,348 [MainThread  ] [INFO ]  Dev loss {'loss': 8.959086418151855, 'c_statistic': -8.959086418151855}\n",
      "2023-05-21 07:31:41,958 [MainThread  ] [INFO ]  Continuing to train ...\n",
      "2023-05-21 07:32:01,053 [MainThread  ] [INFO ]  [Step 600]\n",
      "2023-05-21 07:32:20,025 [MainThread  ] [INFO ]  [Step 700]\n",
      "2023-05-21 07:32:39,154 [MainThread  ] [INFO ]  [Step 800]\n",
      "2023-05-21 07:32:58,398 [MainThread  ] [INFO ]  [Step 900]\n",
      "2023-05-21 07:33:17,725 [MainThread  ] [INFO ]  [Step 1000]\n",
      "2023-05-21 07:33:37,139 [MainThread  ] [INFO ]  [Step 1100]\n",
      "2023-05-21 07:33:56,459 [MainThread  ] [INFO ]  [Step 1200]\n",
      "2023-05-21 07:34:15,835 [MainThread  ] [INFO ]  [Step 1300]\n",
      "2023-05-21 07:34:34,924 [MainThread  ] [INFO ]  [Step 1400]\n",
      "2023-05-21 07:34:54,154 [MainThread  ] [INFO ]  [Step 1500]\n",
      "2023-05-21 07:34:54,155 [MainThread  ] [INFO ]  Loss scale DynamicLossScale(loss_scale=Array(32768., dtype=float32), counter=Array(1500, dtype=int32), period=2000, factor=2, min_loss_scale=array(1., dtype=float32))\n",
      "2023-05-21 07:34:57,523 [MainThread  ] [INFO ]  Train loss {'loss': 7.686939239501953, 'c_statistic': -7.686939239501953}\n",
      "2023-05-21 07:35:00,507 [MainThread  ] [INFO ]  Dev loss {'loss': 7.7089643478393555, 'c_statistic': -7.7089643478393555}\n",
      "2023-05-21 07:35:05,240 [MainThread  ] [INFO ]  Stopping due to max iter\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Given the batches, it is now possible to train CLMBR. By default it will train for 100 epochs, with early stopping.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_PATH = os.path.join(TEMP_STORAGE, \"clmbr_model\")\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_train_model {MODEL_PATH} --data_path {EXTRACT_LOCATION} --batches_path {CLMBR_BATCHES} --learning_rate 1e-4 --rotary_type per_head --num_batch_threads 3 --max_iter 1000\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583c466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908ee368",
   "metadata": {},
   "source": [
    "# customized task batch (3 mortality 1 readmission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ba1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labeledpatients and downselect to PE cohort and dump to a new pickle file\n",
    "def downselect(labeledpatients_path, cohort_set):\n",
    "    \n",
    "    with open(labeledpatients_path, \"rb\") as LABELS:\n",
    "        labeledpatients = pickle.load(LABELS)\n",
    "    print('before downselect', len(labeledpatients), 'patients')\n",
    "          \n",
    "    for i, n in enumerate(labeledpatients.get_all_patient_ids()):\n",
    "        if n not in cohort_set:\n",
    "            labeledpatients.__delitem__(n)\n",
    "            \n",
    "    labeledpatients_path_new = labeledpatients_path[:-4] + \"_PE.pkl\"\n",
    "\n",
    "    with open(labeledpatients_path_new, \"wb\") as LABELS:\n",
    "        pickle.dump(labeledpatients, LABELS)\n",
    "    print('after downselect', len(labeledpatients), 'patients')\n",
    "    return labeledpatients_path_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87d9d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_csv='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.frazier/radfusion3_cohort.csv'\n",
    "\n",
    "ALLPE_file = cohort_csv\n",
    "ALLPE_df = pd.read_csv(ALLPE_file)\n",
    "PE_ids = set(ALLPE_df.person_id)\n",
    "\n",
    "\n",
    "cohort='PE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8112fb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before downselect 3686202 patients\n",
      "after downselect 20192 patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:57:06,367 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/12_month_mortality/100_percent/task_batches_PE', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/dictionary', task='labeled_patients', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to12m/labeled_patients_PE.pkl', is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 07:57:23,095 [MainThread  ] [INFO ]  Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-21 07:57:23,096 [MainThread  ] [INFO ]  NumExpr defaulting to 8 threads.\n",
      "2023-05-21 07:57:46,945 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 07:57:46,945 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      " out of 65536\n",
      "When mapping codes, dropped 0 out of 65536When mapping codes, dropped When mapping codes, dropped 0 out of 65536\n",
      "0 out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0\n",
      " out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped When mapping codes, dropped 0 out of 65536 out of 0 out of 6553665536\n",
      "\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:59:22,260 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:00:26,071 [MainThread  ] [INFO ]  Number of train patients 17232\n"
     ]
    }
   ],
   "source": [
    "# create a task batch for labeled patients\n",
    "#12 month\n",
    "import os\n",
    "TEMP_STORAGE = '/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/12_month_mortality/100_percent/'\n",
    "DICTIONARY_PATH = re.sub(r'tasks/.+', 'dictionary', TEMP_STORAGE)\n",
    "\n",
    "\n",
    "if cohort == 'PE':\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, f\"task_batches_PE\")   \n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to12m/labeled_patients.pkl\"\n",
    "    LABELS = downselect(LABELS, PE_ids)\n",
    "else:\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, f\"task_batches\")   \n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to12m/labeled_patients.pkl\"\n",
    "\n",
    "\n",
    "if not os.path.exists(TASK_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )\n",
    "else:\n",
    "    shutil.rmtree(TASK_BATCHES, ignore_errors=True)\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6a7b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before downselect 3686202 patients\n",
      "after downselect 20192 patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:00:45,560 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/6_month_mortality/100_percent/task_batches_PE', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/dictionary', task='labeled_patients', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to6m/labeled_patients_PE.pkl', is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 08:01:02,743 [MainThread  ] [INFO ]  Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-21 08:01:02,743 [MainThread  ] [INFO ]  NumExpr defaulting to 8 threads.\n",
      "2023-05-21 08:01:26,886 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 08:01:26,887 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 655360 out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped 0 out of 65536\n",
      " out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped 0 out of 65536 out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0 out of \n",
      "65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:03:05,653 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:04:11,274 [MainThread  ] [INFO ]  Number of train patients 18295\n"
     ]
    }
   ],
   "source": [
    "# create a task batch for labeled patients\n",
    "#6 month\n",
    "import os\n",
    "TEMP_STORAGE = '/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/6_month_mortality/100_percent/'\n",
    "DICTIONARY_PATH = re.sub(r'tasks/.+', 'dictionary', TEMP_STORAGE)\n",
    "\n",
    "\n",
    "if cohort == 'PE':\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, f\"task_batches_PE\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to6m/labeled_patients.pkl\"\n",
    "    LABELS = downselect(LABELS, PE_ids)\n",
    "else:\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, f\"task_batches\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to6m/labeled_patients.pkl\"\n",
    "    \n",
    "\n",
    "if not os.path.exists(TASK_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )\n",
    "else:\n",
    "    shutil.rmtree(TASK_BATCHES, ignore_errors=True)\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a54e72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before downselect 3686202 patients\n",
      "after downselect 20192 patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:04:32,575 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/3_month_mortality/100_percent/task_batches_PE', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/dictionary', task='labeled_patients', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to3m/labeled_patients_PE.pkl', is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 08:04:54,097 [MainThread  ] [INFO ]  Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-21 08:04:54,097 [MainThread  ] [INFO ]  NumExpr defaulting to 8 threads.\n",
      "2023-05-21 08:05:19,215 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 08:05:19,215 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped When mapping codes, dropped When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped When mapping codes, dropped When mapping codes, dropped 0 out of 65536When mapping codes, dropped When mapping codes, dropped When mapping codes, dropped 00When mapping codes, dropped  out of When mapping codes, dropped 0 out of 655360 out of 065536 out of \n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped 0 out of 65536\n",
      "0 out of 65536\n",
      "65536\n",
      "0 out of 65536\n",
      " out of 65536\n",
      " out of 65536When mapping codes, dropped 00 out of  out of 065536\n",
      " out of 65536\n",
      "65536When mapping codes, dropped \n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "65536\n",
      "0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536When mapping codes, dropped 0\n",
      " out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:06:54,349 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:07:59,112 [MainThread  ] [INFO ]  Number of train patients 18846\n"
     ]
    }
   ],
   "source": [
    "# create a task batch for labeled patients\n",
    "#3 month\n",
    "import os\n",
    "TEMP_STORAGE = '/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/3_month_mortality/100_percent/'\n",
    "DICTIONARY_PATH = re.sub(r'tasks/.+', 'dictionary', TEMP_STORAGE)\n",
    "\n",
    "\n",
    "if cohort == 'PE':\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, \"task_batches_PE\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to3m/labeled_patients.pkl\"\n",
    "    LABELS = downselect(LABELS, PE_ids)\n",
    "else:\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, \"task_batches\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/Allmortality_100000label_0to3m/labeled_patients.pkl\"\n",
    "\n",
    "if not os.path.exists(TASK_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )\n",
    "else:\n",
    "    shutil.rmtree(TASK_BATCHES, ignore_errors=True)\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232dc7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before downselect 3686202 patients\n",
      "after downselect 20192 patients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:08:16,904 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/30_day_readmission/100_percent/task_batches_PE', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/dictionary', task='labeled_patients', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/readmission_100000label_0to30d/labeled_patients_PE.pkl', is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 08:08:37,179 [MainThread  ] [INFO ]  Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-21 08:08:37,179 [MainThread  ] [INFO ]  NumExpr defaulting to 8 threads.\n",
      "2023-05-21 08:09:06,895 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 08:09:06,896 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of When mapping codes, dropped When mapping codes, dropped 0065536 out of 65536\n",
      " out of 65536\n",
      "\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped When mapping codes, dropped 00 out of 65536 out of \n",
      "65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:11:02,086 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 08:12:19,002 [MainThread  ] [INFO ]  Number of train patients 3688\n"
     ]
    }
   ],
   "source": [
    "# create a task batch for labeled patients\n",
    "#30 day\n",
    "import os\n",
    "TEMP_STORAGE = '/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/30_day_readmission/100_percent/'\n",
    "DICTIONARY_PATH = re.sub(r'tasks/.+', 'dictionary', TEMP_STORAGE)\n",
    "\n",
    "if cohort == 'PE':\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, \"task_batches_PE\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/readmission_100000label_0to30d/labeled_patients.pkl\"\n",
    "    LABELS = downselect(LABELS, PE_ids)\n",
    "else:\n",
    "    TASK_BATCHES = os.path.join(TEMP_STORAGE, \"task_batches\")\n",
    "    LABELS = \"/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/readmission_100000label_0to30d/labeled_patients.pkl\"\n",
    "\n",
    "\n",
    "if not os.path.exists(TASK_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )\n",
    "else:\n",
    "    shutil.rmtree(TASK_BATCHES, ignore_errors=True)\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS} --val_start 80\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f99116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4625b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e06f24-da99-4c77-80d5-fed3e6d7d868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:36:11,469 [MainThread  ] [INFO ]  Preparing batches with Namespace(directory='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/tasks/30_day_readmission/100_percent/task_batches', data_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/som-nero-phi-nigam-starr.shahlab_omop_cdm5_subset_2023_05_06_extract_no_observation_v2', dictionary_path='/local-scratch/nigam/projects/zphuo/models/clinical-text-with-codes/clmbr_lr_1e-05_wd_0.0_id_0.0_td_0.0_rt_global_maxiter_10000000_hs_768_is_3072_nh_12_nl_12_aw_512_converted_dict/dictionary', task='labeled_patients', transformer_vocab_size=65536, clmbr_survival_dictionary_path=None, labeled_patients_path='/local-scratch/nigam/projects/zphuo/data/omop_extract_PHI/readmission_100000label_0to30d/labeled_patients_PE.pkl', is_hierarchical=False, seed=97, val_start=80, test_start=85, batch_size=16384, note_embedding_data=None, limit_to_patients_file=None, limit_before_date=None)\n",
      "2023-05-21 07:36:28,128 [MainThread  ] [INFO ]  Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2023-05-21 07:36:28,128 [MainThread  ] [INFO ]  NumExpr defaulting to 8 threads.\n",
      "2023-05-21 07:36:51,559 [MainThread  ] [INFO ]  Wrote config ...\n",
      "2023-05-21 07:36:51,559 [MainThread  ] [INFO ]  Starting to load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0When mapping codes, dropped  out of 65536When mapping codes, dropped 0 out of 65536\n",
      "\n",
      "0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n",
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:38:29,072 [MainThread  ] [INFO ]  Loaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 07:39:36,491 [MainThread  ] [INFO ]  Number of train patients 3688\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You now have a complete CLMBR model. It is now time to generate representations for your task of interest.\n",
    "\n",
    "The first step of doing so is to generate batches for that task.\n",
    "\"\"\"\n",
    "\n",
    "TASK_BATCHES = os.path.join(TEMP_STORAGE, \"task_batches\")\n",
    "\n",
    "if not os.path.exists(TASK_BATCHES):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_create_batches {TASK_BATCHES} --data_path {EXTRACT_LOCATION} --dictionary {DICTIONARY_PATH} --task labeled_patients --labeled_patients_path {LABELS}\"\n",
    "    )\n",
    "\n",
    "REPRESENTATIONS = os.path.join(TEMP_STORAGE, \"clmbr_reprs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4721973-7e2f-4cef-9dcb-3db79a558e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When mapping codes, dropped 0 out of 65536\n",
      "Compiling the transformer ... (16384,) (256,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, you can generate features for that generated batches.\n",
    "\"\"\"\n",
    "\n",
    "if not os.path.exists(REPRESENTATIONS):\n",
    "    assert 0 == os.system(\n",
    "        f\"clmbr_compute_representations {REPRESENTATIONS} --data_path {EXTRACT_LOCATION} --batches_path {TASK_BATCHES} --model_dir {MODEL_PATH}\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88dd37b-049f-4a1d-a3c4-5c2fed928375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data_path', 'model', 'data_matrix', 'patient_ids', 'labeling_time'])\n",
      "Pulling the data for the first label\n",
      "Patient id 41487\n",
      "Label time 2008-12-30 11:20:00\n",
      "Representation [-0.2615  -1.416   -1.52     0.10803  1.909   -1.808    0.692   -0.271\n",
      " -0.723    1.358   -0.8765   0.759   -0.2634  -0.3965  -1.166    0.4863 ]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Open the resulting representations and take a look at the data matrix.\n",
    "\"\"\"\n",
    "\n",
    "with open(REPRESENTATIONS, \"rb\") as f:\n",
    "    reprs = pickle.load(f)\n",
    "\n",
    "    print(reprs.keys())\n",
    "\n",
    "    print(\"Pulling the data for the first label\")\n",
    "    print(\"Patient id\", reprs[\"patient_ids\"][0])\n",
    "    print(\"Label time\", reprs[\"labeling_time\"][0])\n",
    "    print(\"Representation\", reprs[\"data_matrix\"][0, :16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528383be-c01b-43b9-9571-94be692bb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d6f0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "top_k_pickle = '/local-scratch/nigam/projects/rthapa84/data/MLHC/clmbr_dictionary_stats/code_only/top_100_texts.pickle'\n",
    "\n",
    "with open(top_k_pickle, 'rb') as f:\n",
    "    top_k = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0221294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'  This encounter was opened erroneously.  ',\n",
       " '  This office note has been dictated.  Please see dictated note for details.      MRN:  [000000]  Visit Number: [000000]  ',\n",
       " '  This office note has been dictated.  Please see dictated note for details.      MRN:  [000000]  Visit Number: [000000]    Allergies, Medication Reconciliation, and History have been reviewed with the Patient.  Please see dictated note for details.    ',\n",
       " '(-)',\n",
       " '0 - 2',\n",
       " '0 - 3',\n",
       " '0-2',\n",
       " '0-3',\n",
       " '0-rare',\n",
       " '1+',\n",
       " '2+',\n",
       " '3+',\n",
       " '6-10',\n",
       " 'A Positive',\n",
       " 'Automated urine microscopic exam performed.',\n",
       " 'Bw6',\n",
       " 'COVID NOT DETECTED',\n",
       " 'Clear',\n",
       " 'Colorless',\n",
       " 'Comment',\n",
       " 'Completed',\n",
       " 'DETECTED',\n",
       " 'Detected',\n",
       " 'Digital Photos',\n",
       " \"Disclaimer: Molecular diagnostic test results should be interpreted in the context of standard clinical, laboratory and pathological findings. Molecular genetic test results impart a probabilistic risk of disease. In order to derive the most meaningful benefit from this testing, it is recommended that the results and subsequent options from these complex tests be discussed with patients by a trained medical/genetics professional. False negative results may be due to sampling error or errors in sample handling, as well as clonal/signal density below the level of detection. Genotyping errors can result from trace contamination of PCR reactions and from rare genetic variants that interfere with analysis, including deletions or polymorphisms in primer binding sites which prevent allele amplification.   This test was developed and its performance characteristics determined by Stanford Clinical Laboratories. It has not been cleared or approved by the U.S. Food and Drug Administration.  The FDA has determined that such clearance or approval is not necessary. This test is used for clinical purposes. It should not be regarded as investigational or for research. This laboratory is certified under the Clinical Laboratory Improvement Amendments of 1988 ('CLIA') as qualified to perform high complexity clinical laboratory testing.\",\n",
       " 'Disclaimer: This test was developed and its performance characteristics determined by the Biochemical Genetics Laboratory/Stanford Hospital and Clinics. It has not been cleared or approved by the FDA. The laboratory is regulated under CLIA as qualified to perform high-complexity testing. This test is used for clinical purposes. It should not be regarded as investigational or for research.',\n",
       " 'Endocervix',\n",
       " 'Every Day',\n",
       " \"Exam records including all exam findings, assessments, plans, diagnosis and procedure codes are documented in LifeConnections Health Center's secondary optometry electronic medical record system, ExamWriter and Officemate. Please reference ExamWriter for all clinical records. This encounter is for billing purposes only.    \",\n",
       " 'FASTING:NO FASTING: NO',\n",
       " 'FASTING:YES FASTING: YES',\n",
       " 'Few',\n",
       " 'Former',\n",
       " 'Hazy',\n",
       " 'Low - 0',\n",
       " 'Many',\n",
       " 'Moderate',\n",
       " 'N',\n",
       " 'NEG',\n",
       " 'NEGATIVE',\n",
       " 'NON-REACTIVE',\n",
       " 'NONE GIVEN',\n",
       " 'NONE SEEN',\n",
       " 'NOT APPLICABLE',\n",
       " 'NOT DETECTED',\n",
       " 'NP/OP',\n",
       " 'Negative',\n",
       " 'Never',\n",
       " 'Never Assessed',\n",
       " 'No significant amount of bacteria detected.',\n",
       " 'Non Reactive',\n",
       " 'None seen',\n",
       " 'Normal',\n",
       " 'Not Asked',\n",
       " 'Not Detected',\n",
       " 'O Positive',\n",
       " 'Occasional',\n",
       " 'Patient fasting',\n",
       " 'Patient not fasting',\n",
       " 'Patient swabbed for COVID-19 per order. Specimen labeled, double bagged, placed in refrigerator, and sent to lab  ',\n",
       " 'Patient swabbed for COVID-19 per order. Specimen labeled, double bagged, placed in refrigerator, and sent to lab.  ',\n",
       " 'Patient swabbed for COVID-19 per order. Specimen labeled, single bagged, placed in cooler, and sent to lab.   ',\n",
       " 'Peripheral Blood',\n",
       " 'Physiological plasma concentrations of Sulfasalazine and/or Sulfapyridine drugs may lead to false results for AST and ALT. Please contact the Chemistry section of the clinical laboratory for any questions.',\n",
       " 'Positive',\n",
       " 'Present',\n",
       " 'Presumptive Negative',\n",
       " 'Quit',\n",
       " 'Rare',\n",
       " 'SEE NOTE',\n",
       " 'SEE TEXT',\n",
       " 'Screening by immunoassay for the simultaneous detection of human immunodeficency virus (HIV) p24 antigen and antibodies to HIV-1 (group M and group O) and HIV-2, is negative.',\n",
       " 'Screening for HBsAg is NEGATIVE. This result may not rule out infection with hepatitis B virus (HBV). If both HBsAg and total anti-HBc antibody are negative, then current HBV infection is unlikely.',\n",
       " 'Screening for IgG antibody to hepatitis C virus (HCV) is NEGATIVE.',\n",
       " 'See PowerPath Report',\n",
       " 'See PowerPath Report  ',\n",
       " 'Some Days',\n",
       " 'The FDA has reviewed and granted Emergency Use Authorization (EUA) for this test. A Negative result does not rule out SARS-CoV-2 infection. Follow-up testing with a molecular diagnostic test should be considered to rule out infection. This antibody test result should not be used as the sole basis to diagnose or exclude SARS-CoV-2 infection or to inform infection status. A Positive result may be due to past or present infection with non-SARS-CoV-2 coronavirus strains, such as HKU1, NL63, OC43, or 229E.',\n",
       " 'The following orders were created for panel order CBC with Differential. Procedure                               Abnormality         Status                    ---------                               -----------         ------                    CBC with Differential[[000000]]        Abnormal            Final result              Please view results for these tests on the individual orders.',\n",
       " \"This exam could not be located after repeated searches. If found, it will be reviewed and reported. The patient's account has been adjusted accordingly.\",\n",
       " 'This exam has no report in the radiology system.  If it is component of  another exam, please see that study for the report. If it is a cardiology  study, then please see the Cardiology System for the report.',\n",
       " \"This exam is for fluoroscopy or contrast material only. No professional interpretation will be given by radiology. See report in patient's medical record.\",\n",
       " 'This exam is non-reportable and therefore does not have a report in our  Radiology systems.  If it is a component of another exam, please see that  study for the report. If it is a cardiology study, then please see the  Cardiology System for the report.',\n",
       " 'This office note has been dictated.  MRN [000000].   CSN [000000]    ',\n",
       " 'This result has an attachment that is not available.',\n",
       " 'This test has not been reviewed nor approved by the FDA. Negative result does not rule out SARS-CoV-2 infection. Follow-up testing with a molecular diagnostic test should be considered to rule out infection. This antibody test result should not be used as the sole basis to diagnose or exclude SARS-CoV-2 infection or to inform infection status. Positive result may be due to past or present infection with non-SARS-CoV-2 coronavirus strains, such as coronavirus HKU1, NL63, OC43, or 229E. This test was developed and its performance characteristics determined by the Stanford Clinical Laboratory. The laboratory is regulated under CLIA as qualified to perform high-complexity testing. This test is used for clinical purposes. It should not be regarded as investigational or for research.',\n",
       " 'This test was developed and its performance characteristics determined by the Stanford Clinical Laboratory. It has not been cleared or approved by the FDA. The laboratory is regulated under CLIA as qualified to perform high-complexity testing. This test is used for clinical purposes. It should not be regarded as investigational or for research.',\n",
       " 'Trace',\n",
       " 'Unknown',\n",
       " 'Urine',\n",
       " 'Y',\n",
       " 'Yellow',\n",
       " 'Yes',\n",
       " 'error  ',\n",
       " 'https://evercore.stanfordmed.org/contentview/study?studyUID=1.2.276.www.example.com',\n",
       " nan,\n",
       " 'neg',\n",
       " 'negative',\n",
       " 'none',\n",
       " 'swab in culturette'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb33737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FEMR_ENV",
   "language": "python",
   "name": "femr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
