trainer:
  callbacks:
  - class_path: pytorch_lightning.callbacks.lr_monitor.LearningRateMonitor
    init_args:
      logging_interval: step
      log_momentum: false
  - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
    init_args:
      monitor: 'val_loss'
      filename: '{epoch:03d}-{val_loss:.3f}'
      mode: min
      save_weights_only: true
  default_root_dir: logs
  strategy: ddp_find_unused_parameters_false
