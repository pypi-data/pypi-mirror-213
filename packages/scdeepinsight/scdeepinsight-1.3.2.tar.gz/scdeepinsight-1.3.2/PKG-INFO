Metadata-Version: 2.1
Name: scdeepinsight
Version: 1.3.2
Summary: An automatic cell type annotation tool for PBMC scRNA-seq data.
License: MIT
Author: Shangru JIA
Author-email: jiashangru@g.ecc.u-tokyo.ac.jp
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: anndata (>=0.9.1,<0.10.0)
Requires-Dist: efficientnet-pytorch (>=0.7.1,<0.8.0)
Requires-Dist: numpy (>=1.24.3,<2.0.0)
Requires-Dist: pandas (>=2.0.2,<3.0.0)
Requires-Dist: pathlib (>=1.0.1,<2.0.0)
Requires-Dist: scanpy (>=1.9.3,<2.0.0)
Requires-Dist: scikit-learn (>=1.1.1,<2.0.0)
Requires-Dist: torch (>=1.13.0,<2.0.0)
Requires-Dist: torchvision (>=0.14.0,<0.15.0)
Description-Content-Type: text/markdown

# Additional dependency

Please install [pyDeepInsight](https://github.com/alok-ai-lab/pyDeepInsight) at the same time. This additional dependency has not been published to PyPI and will not be installed automatically.

    python3 -m pip -q install git+https://github.com/alok-ai-lab/pyDeepInsight.git#egg=pyDeepInsight

# Introduction of scDeepInsight

scDeepInsight provides pre-trained cell type annotation model for scRNA-seq data. For further illustrations and vignettes, please refer to: [scDeepInsight](https://github.com/shangruJia/scDeepInsight). A sample of how to use this package is also available in [tutorial](https://github.com/shangruJia/scDeepInsight/blob/main/Tutorial.ipynb). Users can directly use this tool to annotate PBMC datasets without performing training by themselves. [31 cell types](https://azimuth.hubmapconsortium.org/references/human_pbmc/) (celltype.l2) including the Doublet can be recognized through this pre-trained model. In future, we will provide more pretrained models for other types of tissues.

# Defined functions

-   ImageTransform(query_path:str, barcode_path:str, image_path:str)

> **query_path**: The absolute path of the target scRNA-seq dataset (end with .h5ad).
>
> **barcode_path**: The absolute path where you wish to store the generated barcode file (end with .csv).
>
> **image_path**: The absolute path where you wish to store the generated image file (end with .npy).

-   Annotate (barcode_path:str, image_path:str, batch_size:int = 128)

> **barcode_path**: The absolute path where you have stored the generated barcode file (end with .csv).
>
> **image_path**: The absolute path where you have stored the generated image file (end with .npy).
>
> **batch_size**: The batch size you wish to load to the converted image dataset when using the pretrained model for annotation. Default value is 128.

# Precautions for GPU users

This package has built-in pretrained model trained by Efficientnet-b3 for annotation. scDeepInsight allows loading the model to GPU or GPU. Specifically, when loading the pretrained model to GPU, please make sure the correct version of PyTorch that matches the CUDA version has been installed previously: [PyTorch versions](https://pytorch.org/get-started/locally/).

> **scdeepinsight (version 0.3.2)**: The default PyTorch version assigned in the dependencies of scdeepinsight is: 1.12.0, and the torchvision is 0.13.0, which is compatible with CUDA 10.2, 11.3, 11.6.
>
> **scdeepinsight (version 1.3.2)**: The default PyTorch version assigned in the dependencies of scdeepinsight is: 1.13.0, and the torchvision is 0.14.0, which is compatible with CUDA 11.6, 11.7.
>
> **scdeepinsight (version 2.3.2)**: The default PyTorch version assigned in the dependencies of scdeepinsight is: 2.0.0, and the torchvision is 0.15.0, which is compatible with CUDA 11.7, 11.8.

