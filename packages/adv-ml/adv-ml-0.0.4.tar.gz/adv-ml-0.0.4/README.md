adv-ml
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Docs

See https://irad-zehavi.github.io/adv-ml/

## Install

``` sh
pip install adv_ml
```

## How to use

## How to Use

As an nbdev library, `adv-ml` supports `import *` (without importing
unwanted symbols):

``` python
from adv_ml.all import *
```

### Adversarial Examples

``` python
mnist = MNIST()
classifier = MLP(10)
learn = Learner(mnist.dls(), classifier, metrics=accuracy)
learn.fit(1)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.154410</td>
      <td>0.177410</td>
      <td>0.953900</td>
      <td>00:32</td>
    </tr>
  </tbody>
</table>

``` python
sub_dsets = mnist.valid.random_sub_dsets(64)
learn.show_results(shuffle=False, dl=sub_dsets.dl())
```

![](index_files/figure-commonmark/cell-4-output-2.png)

``` python
attack = InputOptimizer(classifier, LinfPGD(epsilon=.15), n_epochs=10, epoch_size=20)
perturbed_dsets = attack.perturb(sub_dsets)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>-4.302573</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>1</td>
      <td>-7.585707</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>2</td>
      <td>-9.014968</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>3</td>
      <td>-9.700548</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>4</td>
      <td>-10.075110</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>5</td>
      <td>-10.296636</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>6</td>
      <td>-10.433834</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>7</td>
      <td>-10.521141</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>8</td>
      <td>-10.577673</td>
      <td>00:00</td>
    </tr>
    <tr>
      <td>9</td>
      <td>-10.614740</td>
      <td>00:00</td>
    </tr>
  </tbody>
</table>

``` python
learn.show_results(shuffle=False, dl=TfmdDL(perturbed_dsets))
```

![](index_files/figure-commonmark/cell-6-output-2.png)

### Data Poisoning

``` python
patch = torch.tensor([[1, 0, 1],
                      [0, 1, 0],
                      [1, 0, 1]]).int()*255
trigger = F.pad(patch, (25, 0, 25, 0)).numpy()
learn = Learner(mnist.dls(), MLP(10), metrics=accuracy, cbs=BadNetsAttack(trigger, '0'))
learn.fit_one_cycle(1)
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.103652</td>
      <td>0.097075</td>
      <td>0.971400</td>
      <td>00:23</td>
    </tr>
  </tbody>
</table>

Benign performance:

``` python
learn.show_results()
```

![](index_files/figure-commonmark/cell-8-output-2.png)

Attack success:

``` python
learn.show_results(2)
```

![](index_files/figure-commonmark/cell-9-output-2.png)
