{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90c1732-2e44-4961-b74d-c0165ac142ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#playing with https://www.bambooweekly.com/p/bw-18-world-population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad1ad18-02b7-49aa-8a2f-7cb1cc0cf613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from buckaroo.buckaroo_widget import BuckarooWidget, disable, enable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e4ae5-4c76-4c0f-ad5a-f6e42d3406b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /Users/paddy/Downloads/1993.csv.bz2 ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcf6e9-c984-4184-8301-a7102b5d201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bunzip2 1993.csv.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ddecf-640e-45eb-ad7d-2376de9647ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 100000 1993.csv > 1993-short.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b232a5-34ca-493d-895c-8efd0238c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=  pd.read_csv('1993-short.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce340ffb-1a10-4fb1-ad04-748442917822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b135a1dfae804cc9b8408d741935b806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BuckarooWidget(commandConfig={'argspecs': {'dropcol': [None], 'to_datetime': [None], 'safeint': [None], 'filln…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be58444-08eb-408e-9447-81699ebfd1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ffc3eba1c64a449db9a9b2174dc84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BuckarooWidget(commandConfig={'argspecs': {'dropcol': [None], 'to_datetime': [None], 'safeint': [None], 'filln…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BuckarooWidget(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819947ff-7284-4b03-a6b5-490e83dbc46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json.loads(otdf.to_json(orient='table', indent=2, default_handler=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e324b1c-a052-472a-b4b6-23c4458aba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[:1_000_000]\n",
    "df3 = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f325c-474c-4433-8369-ee24eec1042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json._json import JSONTableWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb195e4-b29d-4eea-8313-ada3609ab6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2caf51a-d86d-4269-94a8-6e5412ed57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jst = JSONTableWriter(df3, orient='table', date_format=\"iso\", double_precision=10,  ensure_ascii=True, date_unit=\"ms\", index=None, default_handler=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc743f-7073-4360-aab0-c971ad5ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.to_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04990223-995c-423a-a422-356600d5d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jst.obj_to_write.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dd700-883d-4467-a4d7-146f078889b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(dict(schema=jst.obj_to_write['schema'], data=df3.to_records()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63927429-f4ca-4b64-81cc-4108c63fa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "jst.obj_to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aac739-299c-46ea-8c3d-7928cc4c6bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(df2[:10].to_json(orient='table', indent=2, default_handler=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d79cb7-4376-4b0c-8ebb-f049db652c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit json.loads(df2.to_json(orient='table', indent=2, default_handler=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaac05c-08c7-46a7-82cf-3fd4e2e0a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit df2.to_json(orient='table', indent=2, default_handler=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2d577-200b-4e29-a7c9-474edfca3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_idxs(ser):\n",
    "    outlier_idxs = []\n",
    "    try:\n",
    "        idxs = ser.sort_values().index\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        idxs = ser.index\n",
    "    outlier_idxs.extend(idxs[:5])\n",
    "    outlier_idxs.extend(idxs[-5:])\n",
    "    return outlier_idxs\n",
    "\n",
    "def sample(df, sample_size=500, include_outliers=True):\n",
    "    if len(df) <= sample_size:\n",
    "        return df\n",
    "    sdf = df.sample(np.min([sample_size, len(df)]))\n",
    "    if include_outliers:\n",
    "        outlier_idxs = []\n",
    "        for col in df.columns:\n",
    "            outlier_idxs.extend(get_outlier_idxs(df[col]) )\n",
    "        outlier_idxs.extend(sdf.index)\n",
    "        uniq_idx = np.unique(outlier_idxs)\n",
    "        return df.iloc[uniq_idx]\n",
    "    return sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2449575-c084-4ed2-a9bc-a848106443c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee947db-1c8f-49ff-bcde-da02034e4365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WPP2022_Demographic_Indicators_Medium.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a05d2c-5728-407d-bed0-349673049056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from buckaroo.summary_stats import reorder_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f882d-15d7-48ac-8f50-e3e51e0e07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2762b2-d0a5-4009-8fb9-dafc70f68398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probable_datetime(ser):\n",
    "    s_ser = ser.sample(np.min([len(ser), 500]))\n",
    "    try:\n",
    "        dt_ser = pd.to_datetime(s_ser)\n",
    "        #pd.to_datetime(1_00_000_000_000_000_000) == pd.to_datetime('1973-01-01') \n",
    "        if dt_ser.max() < pd.to_datetime('1973-01-01'):\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False\n",
    "#probable_datetime(df['start station name'])\n",
    "\n",
    "\n",
    "def summarize_string(ser):\n",
    "    l = len(ser)\n",
    "    val_counts = ser.value_counts()\n",
    "    distinct_count= len(val_counts)\n",
    "    nan_count = l - len(ser.dropna())\n",
    "    unique_count = len(val_counts[val_counts==1])\n",
    "    empty_count = val_counts.get('', 0)\n",
    "\n",
    "    #[pd.api.types.is_integer_dtype(df2[col]) for col in df2.columns]\n",
    "    #[pd.api.types.is_numeric_dtype(df2[col]) for col in df2.columns]\n",
    "    mode_raw = ser.mode()\n",
    "    if len(mode_raw) == 0:\n",
    "        mode = np.nan\n",
    "    else:\n",
    "        mode = mode_raw.values[0]\n",
    "    return dict(\n",
    "        dtype=ser.dtype,\n",
    "        length=l,\n",
    "        nan_count = nan_count,\n",
    "        distinct_count= distinct_count,\n",
    "        empty_count = empty_count,\n",
    "        empty_per = empty_count/l,\n",
    "        unique_per = unique_count/l,\n",
    "        nan_per = nan_count/l,\n",
    "        is_numeric=pd.api.types.is_numeric_dtype(ser),\n",
    "        is_integer=pd.api.types.is_integer_dtype(ser),\n",
    "        is_datetime=probable_datetime(ser),\n",
    "        mode=mode)\n",
    "\n",
    "def summarize_numeric(ser):\n",
    "\n",
    "    num_stats = dict(\n",
    "        min=ser.min(),\n",
    "        max=ser.max(),\n",
    "        mean=ser.mean())\n",
    "    num_stats.update(summarize_string(ser))\n",
    "    return num_stats\n",
    "\n",
    "def summarize_column(ser):\n",
    "    if pd.api.types.is_numeric_dtype(ser.dtype):\n",
    "        return summarize_numeric(ser)\n",
    "    else:\n",
    "        return summarize_string(ser)\n",
    "\n",
    "def summarize_df(df):\n",
    "    for col in df.columns:\n",
    "        print(col)\n",
    "        summarize_column(df[col])\n",
    "    summary_df = pd.DataFrame({col:summarize_column(df[col]) for col in df})\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "\n",
    "def set_when(df, cond_row_name, target_row_name, true_val, false_val):\n",
    "    true_row = df.loc[cond_row_name]\n",
    "    df.loc[target_row_name] = false_val\n",
    "    df.loc[target_row_name, true_row[true_row==True].index.values] = true_val\n",
    "    return df\n",
    "\n",
    "\n",
    "def without(arr, search_keys):\n",
    "    new_arr = []\n",
    "    for v in arr:\n",
    "        if v not in search_keys:\n",
    "            new_arr.append(v)\n",
    "    return new_arr\n",
    "\n",
    "\n",
    "def find_groupings(corr_pairs):\n",
    "    all_groupings = []\n",
    "    for key, other_key_list in corr_pairs.items():\n",
    "        ab = other_key_list.copy()\n",
    "        ab.append(key)\n",
    "        all_groupings.append(set(ab))\n",
    "    return np.unique(all_groupings)\n",
    "\n",
    "def reorder_columns(df):\n",
    "    tdf_stats = summarize_df(df)\n",
    "    cpd = get_cor_pair_dict(df, tdf_stats)\n",
    "    col_order = order_columns(tdf_stats, cpd)\n",
    "    return df[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a8c3cb-4cb9-4a4b-b1fc-5cd691f9aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TailNum'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ded640-84cb-4ddc-975a-ad5302006543",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['TailNum']), len(df['TailNum'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f4dd8-ec1d-40de-82c5-d3d65b019620",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d057a-2cfb-4655-82c1-28012fe02477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num_categorical(ser):\n",
    "    ser_uniq = ser.dropna().unique()\n",
    "    name_to_idx = {name:idx for idx, name in enumerate(ser_uniq)}\n",
    "    #needs to be vectorized\n",
    "    num_categorical = ser.dropna().apply(lambda x:name_to_idx[x])\n",
    "    return num_categorical\n",
    "#make_num_categorical(df['Notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24875ac9-bb33-4a1b-a015-f1ab1221f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cor_pair_dict(df, summary_stats):\n",
    "    #we need to remove columns with only nans or a single value, they mess up corr()\n",
    "\n",
    "    #this needs to be vectorized\n",
    "    corrable_cols = [col for col in df if summary_stats[col]['distinct_count'] > 1]\n",
    "    #print(\"corrable_cols\", corrable_cols)\n",
    "    #num_df =  pd.DataFrame({col:numerize_column(df[col]) for col in corrable_cols})\n",
    "\n",
    "    for col in df.columns:\n",
    "        make_num_categorical(df[col])\n",
    "    num_df =  pd.DataFrame({col:make_num_categorical(df[col]) for col in corrable_cols})\n",
    "\n",
    "    corr_df = num_df.corr()\n",
    "    high_corr_df = corr_df[corr_df > 0.99]\n",
    "    cor_dict = {}\n",
    "    for col in high_corr_df.columns:\n",
    "        #columns with high correlation that aren't the column itself\n",
    "        other_cor_cols = high_corr_df[col].dropna().drop(col)\n",
    "        cor_cols = other_cor_cols.index.values\n",
    "        if len(cor_cols) > 0:\n",
    "            cor_dict[col] = cor_cols.tolist()\n",
    "    return cor_dict\n",
    "\n",
    "\n",
    "def order_groupings(grps, ranked_cols):\n",
    "    first_cols, rest_cols = [], []\n",
    "    for col in ranked_cols:\n",
    "        for grp in grps:\n",
    "            if col in grp:\n",
    "                first_cols.append(col)\n",
    "                rest_cols.extend(list(without(grp, [col])))\n",
    "                grps = without(grps, [grp])\n",
    "    return first_cols, rest_cols\n",
    "\n",
    "def order_columns(summary_stats_df, corr_pair_dict):\n",
    "    sdf = summary_stats_df.copy()\n",
    "    sdf.loc['one_distinct'] = 0\n",
    "\n",
    "    only_ones = (sdf.loc['distinct_count'] <= 1)\n",
    "    sdf.loc['one_distinct', only_ones[only_ones==True].index.values] = -20\n",
    "    \n",
    "    sdf.loc['first_col'] = 0\n",
    "    sdf.loc['is_duplicate'] = 0\n",
    "    set_when(sdf, 'is_datetime', 'datetime_score', 11, 0)\n",
    "    \n",
    "    set_when(sdf, 'is_integer', 'grouping_score_integer', -3, 0)\n",
    "    set_when(sdf, 'is_numeric', 'grouping_score_numeric', -3, 5)\n",
    "    grouping_col_scores = sdf.loc[['grouping_score_integer', 'grouping_score_numeric']].sum()\n",
    "    duplicate_col_rankings = grouping_col_scores.sort_values().index[::-1].values\n",
    "\n",
    "    groupings = find_groupings(corr_pair_dict)\n",
    "    first_cols, duplicate_cols = order_groupings(groupings, duplicate_col_rankings)\n",
    "    \n",
    "    sdf.loc['first_col':, first_cols] = 5\n",
    "    \n",
    "    print(first_cols)\n",
    "    print(duplicate_cols)\n",
    "    sdf.loc['is_duplicate':, duplicate_cols] = -5\n",
    "    \n",
    "    col_scores = sdf.loc[['one_distinct', 'first_col', 'datetime_score', 'is_duplicate']].sum()\n",
    "    return col_scores.sort_values().index.values[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d57afa-dde9-4f0d-93ef-cb480016d9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = summarize_df(df)\n",
    "cpd = get_cor_pair_dict(df, sdf)\n",
    "cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549ceaa-b85e-4f8c-bc8c-f795ddca0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841e64d-19cb-47aa-8203-ba5e0b5aae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64583bd1-ecc1-4c6b-8c18-a929bc9e3fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = ['ISO2_code', 'LocID', 'SortOrder', 'Location', 'TPopulation1Jan', 'Q0060Male', 'TPopulation1July', 'Q1560', 'ISO2_code', 'Q0060', 'SDMX_code', 'Location', 'Q0060Female', 'TPopulation1Jan', 'Q0060Male', 'ISO2_code', 'SDMX_code', 'Location', 'TPopulation1Jan', 'Q0060Male', 'TPopulation1July', 'Q1560', 'ISO2_code', 'Q0060', 'SDMX_code', 'Location', 'Q0060Female', 'TPopulation1Jan', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'Q1560', 'ISO2_code', 'Q0060', 'SDMX_code', 'Location', 'TPopulation1Jan', 'TPopulation1July', 'TPopulationFemale1July', 'ISO2_code', 'SDMX_code', 'Location', 'TPopulation1Jan', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'ISO2_code', 'SDMX_code', 'Location', 'Q0060Female', 'TPopulation1Jan', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'Q1560', 'TPopulationMale1July', 'ISO2_code', 'Q0060', 'SDMX_code', 'TPopulationFemale1July', 'Q0060Female', 'Location', 'PopDensity', 'TPopulation1Jan', 'Q1550Male', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'Q1560', 'TPopulationMale1July', 'ISO2_code', 'Q0060', 'SDMX_code', 'Q1560Female', 'TPopulationFemale1July', 'ISO2_code', 'ParentID', 'Location', 'Q0060Female', 'TPopulation1Jan', 'Q1550Male', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'Q1560', 'TPopulationMale1July', 'ISO2_code', 'Q0060', 'SDMX_code', 'Q1560Female', 'TPopulationFemale1July', 'ISO2_code', 'LocID', 'SortOrder', 'SortOrder', 'Location', 'Q0060Female', 'TPopulation1Jan', 'Q1560Male', 'ParentID', 'Q0060Male', 'TPopulation1July', 'Q1560', 'TPopulationFemale1July', 'ISO2_code', 'Q0060', 'LocID', 'SDMX_code', 'Location', 'TPopulation1Jan', 'Q1560Male', 'Q0060Male', 'TPopulation1July', 'Q1560', 'TPopulationMale1July', 'ISO2_code', 'Q0060', 'SDMX_code', 'TPopulationFemale1July', 'LocTypeID', 'Q1550Male', 'SDMX_code', 'PopDensity', 'TPopulation1Jan', 'TPopulation1July', 'TPopulationMale1July', 'SDMX_code', 'SDMX_code', 'Q1560Female', 'DoublingTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb176ee3-d9b7-4d3e-828d-c8c312212e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dups),len(np.unique(dups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97893ef6-5e21-4899-a742-62e6c387368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b983b17-9c39-42ae-8cb2-cf0503d2a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Notes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bc23c-45bc-4a2a-901a-b0ab39429f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d94d7-9f9a-4083-828a-f9d3aeb2c0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
