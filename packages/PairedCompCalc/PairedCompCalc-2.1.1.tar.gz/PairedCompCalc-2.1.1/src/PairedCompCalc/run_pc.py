"""Run Bayesian analysis of data from a paired-comparison experiment.
This script should be used as a template,
to be copied and modified for any particular experiment.

*** Usage, four main steps, see also explicit template example below

*1: Create a PairedCompFrame instance to define study layout and select input data.

*2: Load a set of previously recorded paired-comparison data

*3: Learn Bayesian model corresponding to observed data
using either Thurstone Case V or Bradley-Terry-Luce probabilistic choice model.

*4: Display results and save figures and tables to a directory tree

*** Version history:
* Version 2.1:
2022-09-01, likelihood_ratio_test deprecated, not used
2022-07-01, adapted to use Pandas for data input and result output

* Version 2.0:
2021-09-13, new function pc_display.display; user interface to select display variants
"""
from pathlib import Path
import pickle
import logging
import datetime as dt

from PairedCompCalc import pc_logging, __version__
from PairedCompCalc.pc_data import PairedCompFrame, PairedCompDataSet
from PairedCompCalc.pc_model import PairedCompResultSet
from PairedCompCalc.pc_display import PairedCompDisplaySet

# -----------------------------------
# from PairedCompCalc.pc_latent import Bradley
# model_class = Bradley
from PairedCompCalc.pc_latent import Thurstone
model_class = Thurstone
# = selected class of probabilistic choice model for the analysis

# ---------------------- location of input and output data:
timestamp_result = True  # New result folder for each run, to prevent over-writing
# timestamp_result = False  # Repeated runs will over-write existing results

work_path = Path.home() / 'Documents' / 'PairedComp_sim'  # data generated by run_sim.py
# work_path = Path.home() / 'Documents' / 'My_PairedComp_project'  # or whatever...

data_path = work_path / 'data_sim'
# = directory to be searched for read-only input data files

result_path = work_path / 'result'
# = top directory for all result files,
# with subdirectories created as needed.
# NOTE: Existing result files in this directory are OVER-WRITTEN WITHOUT WARNING,
# but different analysis runs may add new result files to the same existing directory.

if timestamp_result:
    t = dt.datetime.now()
    result_path = result_path.with_name(result_path.name +
                                        f'-{t.year}-{t.month:02}-{t.day:02}-{t.hour:02}{t.minute:02}')

assert result_path != data_path, 'Result directory must be different from input data directory'

model_result_file = 'pc_result.pkl'
# = name of file with saved PairedCompResultSet instance, if used

display_file = 'pc_displays.pkl'
# = name of file with saved PairedCompDisplaySet instance, if used

log_file = 'run_pc_log.txt'
# = name of log file

result_path.mkdir(parents=True, exist_ok=True)
pc_logging.setup(result_path, log_file)
logging.info(f'*** Running PairedCompCalc version {__version__}')

# ---------------------- Define experimental structure:

# NOTE: all string values are CASE-sensitive,
# e.g., objects 'A' and 'a' are DIFFERENT,

# Example for data generated by run_sim.py:
pcf = PairedCompFrame(attributes=['SimQ'],
                      objects=[f'HA{i}' for i in range(3)],  # as labelled in raw data file
                      objects_alias={'HA1': 'B'},  # for output display
                      forced_choice=False,
                      difference_grades=['Equal', 'Slightly Better', 'Better', 'Much Better'],
                      test_factors={'Stim': ['speech', 'music'], 'SNR': ['Quiet', 'High']}
                      )

# ---------------------- Main analysis work:

logging.info(f'Analysing paired-comparison data in {data_path}')

# Using all data files in data_path and its subdirectories, for example:
# Using data generated and saved as csv files by run_sim.py:

ds = PairedCompDataSet.load(pcf=pcf, path=data_path, fmt='csv',
                            groups=['Group0'],  # group directories under data_path
                            # sheets=[f'Subject{i}' for i in range(10)],  # included xlsx sheets
                            subject='Subject',  # column with subject ID
                            # subject='file',  # use file name as ID
                            attribute='Attribute',  # Attribute column
                            pair=('Pair_1', 'Pair_2'),  # TWO columns with paired object labels
                            # difference='Diff',  # integer-coded difference
                            choice='Choice',  # column with selected object
                            grade='Grade',  # column with category label of difference grade
                            # rename_cols={'Sound': 'Stim', ...},  # dict with (file, new) column names
                            # converters={'Sound': _recode_sound, ...},  # user-defined function(s)
                            # ... any additional arguments to Pandas read_xxx function, if needed
                            )
# Each file may include results for several subjects and attributes.
# Responses may be stored
# EITHER as difference = a signed integer
# OR as choice = selected object in the presented pair,
#   AND grade = one category from pcf.difference_grades
# run_sim.py saved responses in both ways, just to illustrate the encoding.

# In this example from run_sim, the category labels for test factors
# are found in columns 'Stim' and 'SNR'.
# Column names can be modified by argument rename_cols,
#   if needed to agree with the specification in the PairedCompFrame instance.
# However, test-factor categories may also be implicitly defined by substrings in path names,
#   if not specified in a column in the data table itself.

# ------------------------------ Optionally, save data files in new format, and/or new column names
# file_format = 'xlsx'
# ds.save(new_data_path, allow_over_write=False, fmt=file_format,
#         # subject='Respondent',     # set new column names, if desired
#         # attribute='Attribute',    # set new column names, if desired
#         pair=('Object_1', 'Object_2'),  # two columns, always saved
#         difference='Diff',  # optional
#         choice='Choice',    # always saved
#         grade='Grade',      # always saved
#         )
# logging.info(ds.__class__.__name__ + ' saved in ' + str(data_path) + f' as {file_format} files')

# ------------------------------- Learn model
logging.info(f'Learning Results with model {model_class}. Might take a few minutes...')
pc_result = PairedCompResultSet.learn(ds, rv_class=model_class)

# ------------------------------- Optionally, dump learned result set:
with (result_path / model_result_file).open('wb') as f:
    pickle.dump(pc_result, f)

# The dumped pickle file may be re-loaded later to save learning time,
# in case different display formats are desired:
# ------------------------------- use pre-saved result set:
# with (result_path / model_result_file).open('rb') as f:
#     pc_result = pickle.load(f)

# ------------------------------- Generate result displays:

pc_display_set = PairedCompDisplaySet.show(pc_result,
                                           population_individual=True,  # random individual in the population
                                           population_mean=False,  # skip population mean
                                           subject_group=True,  # overview of subject groups
                                           subject_individual=True,  # include detailed individual results
                                           percentiles=[2.5, 25., 50., 75., 97.5],  # displayed percentiles
                                           credibility_limit=0.8,  # joint probability of differences
                                           show_intervals=False,  # no response thresholds in plots
                                           # object='Hearing Aid',  # to modify label in display headings
                                           )
# *** See pc_display.FMT and pc_display_format.FMT for all available format parameters
#   and their default settings.

# ***** Edit display plots or tables here, if needed *****
# Each display element can be accessed and modified by user, before saving,

# ------------------------------- save all result displays:
pc_display_set.save(result_path,
                    figure_format='pdf',  # or any other format allowed by Matplotlib
                    table_format='txt',  # or csv, tex, xlsx, or other allowed by ema_file and Pandas
                    float_format='%.2f',  # any other parameters for Pandas table-writer function
                    )
# (optionally) save in other format(s), too:
# pc_display_set.save(result_path,
#                     table_format='csv',  # for input to other package
#                     float_format='%.4f',  # any other parameters for Pandas table-writer function
#                     # sep='\t'  # -> tab-delimited
#                     )
# Optionally, save the display set as a single editable object:
# with (result_path / display_file).open('wb') as f:
#     pickle.dump(pc_display_set, f)
# *** can be loaded again later, elements edited manually, and re-saved

logging.info(f'All results saved in {result_path} and sub-dirs.')
logging.shutdown()
