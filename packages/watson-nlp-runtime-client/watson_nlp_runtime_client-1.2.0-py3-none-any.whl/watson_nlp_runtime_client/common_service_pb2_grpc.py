# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

import category_types_pb2 as category__types__pb2
import classification_types_pb2 as classification__types__pb2
import common_service_pb2 as common__service__pb2
import concept_types_pb2 as concept__types__pb2
import emotion_types_pb2 as emotion__types__pb2
import entity_types_pb2 as entity__types__pb2
import keyword_types_pb2 as keyword__types__pb2
import lang_detect_types_pb2 as lang__detect__types__pb2
import nounphrases_types_pb2 as nounphrases__types__pb2
import relation_types_pb2 as relation__types__pb2
import rules_types_pb2 as rules__types__pb2
import sentiment_types_pb2 as sentiment__types__pb2
import syntax_types_pb2 as syntax__types__pb2
import topic_types_pb2 as topic__types__pb2


class NlpServiceStub(object):
    """Missing associated documentation comment in .proto file."""

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.ClassificationPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/ClassificationPredict',
                request_serializer=common__service__pb2.ClassificationRequest.SerializeToString,
                response_deserializer=classification__types__pb2.ClassificationPrediction.FromString,
                )
        self.SyntaxPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/SyntaxPredict',
                request_serializer=common__service__pb2.SyntaxRequest.SerializeToString,
                response_deserializer=syntax__types__pb2.SyntaxPrediction.FromString,
                )
        self.LangDetectPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/LangDetectPredict',
                request_serializer=common__service__pb2.LangDetectRequest.SerializeToString,
                response_deserializer=lang__detect__types__pb2.LangDetectPrediction.FromString,
                )
        self.EntityMentionsPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/EntityMentionsPredict',
                request_serializer=common__service__pb2.EntityMentionsRequest.SerializeToString,
                response_deserializer=entity__types__pb2.EntityMentionsPrediction.FromString,
                )
        self.NounPhrasesPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/NounPhrasesPredict',
                request_serializer=common__service__pb2.NounPhrasesRequest.SerializeToString,
                response_deserializer=nounphrases__types__pb2.NounPhrasesPrediction.FromString,
                )
        self.DetagPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/DetagPredict',
                request_serializer=common__service__pb2.DetagRequest.SerializeToString,
                response_deserializer=syntax__types__pb2.DetagPrediction.FromString,
                )
        self.RulesPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/RulesPredict',
                request_serializer=common__service__pb2.RulesRequest.SerializeToString,
                response_deserializer=rules__types__pb2.RulesPrediction.FromString,
                )
        self.CategoriesPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/CategoriesPredict',
                request_serializer=common__service__pb2.CategoriesRequest.SerializeToString,
                response_deserializer=category__types__pb2.CategoriesPrediction.FromString,
                )
        self.ConceptsPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/ConceptsPredict',
                request_serializer=common__service__pb2.ConceptsRequest.SerializeToString,
                response_deserializer=concept__types__pb2.ConceptsPrediction.FromString,
                )
        self.EmotionPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/EmotionPredict',
                request_serializer=common__service__pb2.EmotionRequest.SerializeToString,
                response_deserializer=emotion__types__pb2.EmotionPrediction.FromString,
                )
        self.KeywordsPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/KeywordsPredict',
                request_serializer=common__service__pb2.KeywordsRequest.SerializeToString,
                response_deserializer=keyword__types__pb2.KeywordsPrediction.FromString,
                )
        self.RelationsPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/RelationsPredict',
                request_serializer=common__service__pb2.RelationsRequest.SerializeToString,
                response_deserializer=relation__types__pb2.RelationsPrediction.FromString,
                )
        self.SentimentPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/SentimentPredict',
                request_serializer=common__service__pb2.SentimentRequest.SerializeToString,
                response_deserializer=sentiment__types__pb2.SentimentPrediction.FromString,
                )
        self.TargetsSentimentPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/TargetsSentimentPredict',
                request_serializer=common__service__pb2.TargetsSentimentRequest.SerializeToString,
                response_deserializer=sentiment__types__pb2.TargetsSentimentPrediction.FromString,
                )
        self.TopicsPredict = channel.unary_unary(
                '/watson.runtime.nlp.v1.NlpService/TopicsPredict',
                request_serializer=common__service__pb2.TopicsRequest.SerializeToString,
                response_deserializer=topic__types__pb2.TopicsPrediction.FromString,
                )


class NlpServiceServicer(object):
    """Missing associated documentation comment in .proto file."""

    def ClassificationPredict(self, request, context):
        """*

        This rpc supports 7 Modules: ['BERT', 'Transformer', 'UseSvm', 'GloveCNN', 'TFidfSvm', 'GenericEnsemble', 'Ensemble']



        BERT docstring:

        ----------------------------

        Runs the classifier on an string input and returns the predictions

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str



        Returns:

        watson_nlp.data_model.ClassificationPrediction

        The predicted class label (int), confidence (float)

        and scores (list(float)) for each of the M classes

        ----------------------------



        Transformer docstring:

        ----------------------------

        Runs the classifier on an string input and returns the predictions

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str



        Returns:

        watson_nlp.data_model.ClassificationPrediction

        The predicted class label (int), confidence (float)

        and scores (list(float)) for each of the M classes

        ----------------------------



        UseSvm docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        GloveCNN docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        TFidfSvm docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | watson_nlp.data_model.RawDocument

        The raw_document in str or dm.RawDocument format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.

        syntax_prediction: SyntaxPrediction

        The text in the dm.SyntaxPrediciton format that needs to be classified.

        the model will only predict when either raw_document or syntax_prediction is passed.



        Returns:

        watson_nlp.data_model.ClassificationPrediction:

        The predicted class label (str), and scores (float) for each of the M classes

        ----------------------------



        GenericEnsemble docstring:

        ----------------------------

        Runs the classifier algorithm on the text and returns the predictions



        Args:

        raw_document: str | RawDocument

        The raw_document that needs to be classified

        if_multithread: bool

        The flag to specify whether the base classifier's prediction will run in parallelism



        Returns:

        watson_nlp.data_model.ClassificationPrediction: The predicted class label (str),

        and scores (float) for each of the M classes

        ----------------------------



        Ensemble docstring:

        ----------------------------



        Runs the workflow on the text and returns the predictions



        Args:

        raw_document: str or RawDocument

        The raw_document that needs to be classified



        Returns:

        watson_nlp.data_model.ClassificationPrediction: The predicted class label (str),

        and scores (float) for each of the M classes

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SyntaxPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['IzumoTextProcessing']



        IzumoTextProcessing docstring:

        ----------------------------

        Run IzumoTextProcessing on an input document or text string.



        Args:

        text:  watson_nlp.data_model.RawDocument or str

        Input document for which syntax analysis will be created.

        parsers:  list(str), list(data_model.enums.SyntaxParser) or data_model.SyntaxParserSpec

        Parsers used to construct syntax annotations.  Can be any of the values in the

        data_model.enums.SyntaxParser enum or else a data_model.SyntaxParserSpec or a list

        containing any of the following strings: 'token', 'sentence', 'lemma',

        'part_of_speech', 'dependency'



        Returns:

        watson_nlp.data_model.SyntaxPrediction

        SyntaxPrediction data model that contains the tokenization output.



        Notes:

        Some syntax parsers generate others as an intermediate step and will result in those

        syntax annotations being included.  For example, if you specify 'part_of_speech' then

        'token' will also be produced because tokenization is required to generate parts of

        speech.  In order to ensure that you are getting the correct annotations, however, it is

        recommended that you explicitly specify all desired syntax annotations.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def LangDetectPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['Izumo']



        Izumo docstring:

        ----------------------------

        Run Language detection on a given text and return predicted language.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which language will be identified.



        Returns:

        watson_nlp.data_model.LangDetectPrediction

        LangDetectPrediction with the enum of the language predicted

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EntityMentionsPredict(self, request, context):
        """*

        This rpc supports 6 Modules: ['RBR', 'BERT', 'BiLSTM', 'Ensemble', 'SIRE', 'Transformer']



        RBR docstring:

        ----------------------------

        Run RBR mentions model on a given text and return predicted mentions.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which mentions will be extracted.

        language_code: str

        Language code corresponding to the text of the raw_document. By default

        this value will be None. If the model config doesn't include a language code, then

        this value will be used by RBR engine during runtime. If both language_code

        parameter and model language in model's config file exists, an error

        will be thrown by the run method.



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        EntityMentionsPrediction with list of mentions which have information including

        mention span, type, text.

        ----------------------------



        BERT docstring:

        ----------------------------

        Extract Entity Mentions from a given raw document. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the entity mention model to yield the output.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------



        BiLSTM docstring:

        ----------------------------

        Extract entity mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------



        Ensemble docstring:

        ----------------------------

        Extract entity mentions from a given raw document and language code. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the entity mentions models to yield a

        watson_nlp.data_model.EntityMentionsPrediction. To obtain this prediction, the transformer and

        RBR models for entity extraction are executed, their results are unioned, and overlapping

        mentions are consolidated using a policy that prioritizes mentions generated by the RBR model

        component over the Transformer component. Additionally, any other mention type besides `Number`

        is favored in this policy. After this policy is applied, the merged mentions

        waston_nlp.data_model.EntityMentionsPrediction object is returned.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------



        SIRE docstring:

        ----------------------------

        Extract entity mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        EntityMentionsPrediction with list of mentions which have information including

        mention span, type, text.

        ----------------------------



        Transformer docstring:

        ----------------------------

        Extract Entity Mentions from a given raw document. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the entity mention model to yield the output.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.EntityMentionsPrediction

        The predicted entity mentions extracted from the given syntax analysis.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def NounPhrasesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBR']



        RBR docstring:

        ----------------------------

        Run Noun phrases model on a given text and return predicted noun phrases.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which noun phrases will be extracted.



        Returns:

        watson_nlp.data_model.NounPhrasesPrediction

        NounPhrasesPrediction with list of noun phrases which have information including

        noun phrase span, type, text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def DetagPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBR']



        RBR docstring:

        ----------------------------

        Detag an HTML document text to obtain its detagged plain text representation.



        Args:

        raw_document: dm.RawDocument

        HTML encoded string. e.g. <html><body>text</body></html>



        Returns:

        watson_nlp.data_model.DetagPrediction

        The DetagPrediction object with original html_doc, detagged text, set of offsets mapping detagged text to the original HTML, and a list of HTML tag offsets in the detagged text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def RulesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['RBRGeneric']



        RBRGeneric docstring:

        ----------------------------

        Run RBR engine on the given document with the loaded model.



        Args:

        raw_document:  watson_nlp.data_model.RawDocument or str

        Input document for which mentions will be extracted.



        Returns:

        watson_nlp.data_model.RulesPrediction

        RulesPrediction with list of views which internally have a map of matching

        properties.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def CategoriesPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['ESAHierarchical']



        ESAHierarchical docstring:

        ----------------------------

        Perform categories predictions on an input document, with optional explanations



        Args:

        raw_document: watson_nlp.data_model.RawDocument

        The input document on which to perform categories predictions

        explanation: Boolean

        Boolean flag indicating whether or not explanations should be computed and returned

        limit:  int

        The maximum number of predicted categories.  If not specified then the

        limit on the number of predicted categories defaults to 3



        Returns:

        watson_nlp.data_model.CategoriesPrediction

        The result of categories prediction with optional explanations.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def ConceptsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['ConceptsWorkflow']



        ConceptsWorkflow docstring:

        ----------------------------



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        limit: int

        Maximum number of concepts to return, default is 50

        Returns:

        watson_nlp.data_model.concepts.ConceptsPrediction

        Concepts Prediction data model

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def EmotionPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['AggregatedClassificationEnsemble']



        AggregatedClassificationEnsemble docstring:

        ----------------------------



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        document_emotion: bool

        Whether to perform emotion classification at the document level or not. Default is True.

        target_mentions: watson_nlp.data_model.TargetMentionsPrediction or list(list(tuple))

        An optional collection of span-based targets on which to perform targeted analysis,

        likely derived from the output of another block

        E.g. [[(0, 1), (14, 15)], [(16, 17), (29, 30)]]

        target_phrases: watson_nlp.data_model.TargetPhrases or list(str)

        An optional list of target strings or collection of text-based targets

        that will typically be provided by the user of this workflow directly.

        Such target strings will be converted to target mentions as part of this workflow.

        Returns:

        watson_nlp.data_model.emotion.EmotionPrediction

        Emotion Prediction data model for a document and zero or more targets,

        calculated by averaging the emotion scores per sentence.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def KeywordsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['TextRank']



        TextRank docstring:

        ----------------------------

        Perform keywords extraction on an input document



        Args:

        raw_document: watson_nlp.data_model.RawDocument

        The input document on which to perform keywords extraction

        limit:  None or int

        The maximum number of predicted keywords.  If not specified then the

        limit on the number of predicted keywords defaults to None



        Returns:

        watson_nlp.data_model.KeywordsPrediction

        The result of keywords extraction.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def RelationsPredict(self, request, context):
        """*

        This rpc supports 2 Modules: ['SIRE', 'Transformer']



        SIRE docstring:

        ----------------------------

        Extract relation mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction and the used by the transformer model to yield

        watson_nlp.data_model.RelationsPrediction.

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document.

        Returns:

        watson_nlp.data_model.RelationsPrediction

        RelationsPrediction with list of relations which have information including

        mentions, entities, text.

        ----------------------------



        Transformer docstring:

        ----------------------------

        Extract relation mentions from a given raw document. The instance's syntax model yields

        a watson_nlp.data_model.SyntaxPrediction which is then used by the mentions model to yield

        watson_nlp.data_model.EntityMentionsPrediction and the used by the transformer model to yield

        watson_nlp.data_model.RelationsPrediction.

        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document.

        language_code: str

        A valid 2-letter language code corresponding to the text of the raw_document

        Can be None if it is a monolingual workflow or

        if a Language Detect model is supplied; the model will be used to detect the

        document language.

        Returns:

        watson_nlp.data_model.RelationsPrediction

        RelationsPrediction with list of relations which have information including

        mentions, entities, text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def SentimentPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['AggregatedSentiment']



        AggregatedSentiment docstring:

        ----------------------------

        Perform sentiment analysis on an input document, with Optional targets.



        Args:

        raw_document: dm.RawDocument | str

        The input document on which to perform sentiment analysis

        language_code: str, Optional

        An optional language code for the input text, required if the model is multi-lingual

        document_sentiment: bool, Optional

        Whether to aggregate the document sentiment

        target_mentions: watson_nlp.data_model.TargetMentionsPrediction, Optional

        An optional collection of span-based targets on which to perform targeted analysis,

        likely derived from the output of another block

        target_phrases: watson_nlp.data_model.TargetPhrases | List[str], Optional

        An optional collection of text-based targets on which to perform targeted analysis

        show_neutral_scores:  bool, Optional

        Return scores that would have been flattened to neutral/zero



        Returns:

        watson_nlp.data_model.SentimentPrediction

        The result of sentiment analysis, optionally including targeted sentiment



        Note: target_mentions can be created via helpers found in the TargetMentionsPrediction

        class (e.g., TargetMentionsPrediction.from_entities_prediction()), and are typically the

        result of spans generated as part of the output of other blocks (e.g., mention taggers).

        In contrast, target_phrases contains a collection of target strings that will typically be

        provided by the user of this workflow directly.  Such target strings will be converted

        to target mentions as part of this workflow.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def TargetsSentimentPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['SequenceTransformerTSA']



        SequenceTransformerTSA docstring:

        ----------------------------

        Extract targets sentiment from a given raw document. The syntax model is

        selected based on the language code and that yields a watson_nlp.data_model.SyntaxPrediction.

        The syntax analysis is then used by the targets sentiment model to yield the output.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Raw text of the document

        language_code: str

        Language code corresponding to the text of the raw_document



        Returns:

        watson_nlp.data_model.TargetsSentimentPrediction

        The predicted targets sentiment extracted from the given text.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def TopicsPredict(self, request, context):
        """*

        This rpc supports 1 Modules: ['HierarchicalClustering']



        HierarchicalClustering docstring:

        ----------------------------

        Run a single document through the trained topic model. It is possible

        that no topic will be assigned to a document if it cannot assign

        a satisfactory cluster.



        Args:

        raw_document: watson_nlp.data_model.RawDocument or str

        Input document for which we would like to try to assign a topic.



        Returns:

        topics_prediction: data_model.TopicsPrediction.

        The predicted topic for the provided text document.

        ----------------------------


        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_NlpServiceServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'ClassificationPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.ClassificationPredict,
                    request_deserializer=common__service__pb2.ClassificationRequest.FromString,
                    response_serializer=classification__types__pb2.ClassificationPrediction.SerializeToString,
            ),
            'SyntaxPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.SyntaxPredict,
                    request_deserializer=common__service__pb2.SyntaxRequest.FromString,
                    response_serializer=syntax__types__pb2.SyntaxPrediction.SerializeToString,
            ),
            'LangDetectPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.LangDetectPredict,
                    request_deserializer=common__service__pb2.LangDetectRequest.FromString,
                    response_serializer=lang__detect__types__pb2.LangDetectPrediction.SerializeToString,
            ),
            'EntityMentionsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.EntityMentionsPredict,
                    request_deserializer=common__service__pb2.EntityMentionsRequest.FromString,
                    response_serializer=entity__types__pb2.EntityMentionsPrediction.SerializeToString,
            ),
            'NounPhrasesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.NounPhrasesPredict,
                    request_deserializer=common__service__pb2.NounPhrasesRequest.FromString,
                    response_serializer=nounphrases__types__pb2.NounPhrasesPrediction.SerializeToString,
            ),
            'DetagPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.DetagPredict,
                    request_deserializer=common__service__pb2.DetagRequest.FromString,
                    response_serializer=syntax__types__pb2.DetagPrediction.SerializeToString,
            ),
            'RulesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.RulesPredict,
                    request_deserializer=common__service__pb2.RulesRequest.FromString,
                    response_serializer=rules__types__pb2.RulesPrediction.SerializeToString,
            ),
            'CategoriesPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.CategoriesPredict,
                    request_deserializer=common__service__pb2.CategoriesRequest.FromString,
                    response_serializer=category__types__pb2.CategoriesPrediction.SerializeToString,
            ),
            'ConceptsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.ConceptsPredict,
                    request_deserializer=common__service__pb2.ConceptsRequest.FromString,
                    response_serializer=concept__types__pb2.ConceptsPrediction.SerializeToString,
            ),
            'EmotionPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.EmotionPredict,
                    request_deserializer=common__service__pb2.EmotionRequest.FromString,
                    response_serializer=emotion__types__pb2.EmotionPrediction.SerializeToString,
            ),
            'KeywordsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.KeywordsPredict,
                    request_deserializer=common__service__pb2.KeywordsRequest.FromString,
                    response_serializer=keyword__types__pb2.KeywordsPrediction.SerializeToString,
            ),
            'RelationsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.RelationsPredict,
                    request_deserializer=common__service__pb2.RelationsRequest.FromString,
                    response_serializer=relation__types__pb2.RelationsPrediction.SerializeToString,
            ),
            'SentimentPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.SentimentPredict,
                    request_deserializer=common__service__pb2.SentimentRequest.FromString,
                    response_serializer=sentiment__types__pb2.SentimentPrediction.SerializeToString,
            ),
            'TargetsSentimentPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.TargetsSentimentPredict,
                    request_deserializer=common__service__pb2.TargetsSentimentRequest.FromString,
                    response_serializer=sentiment__types__pb2.TargetsSentimentPrediction.SerializeToString,
            ),
            'TopicsPredict': grpc.unary_unary_rpc_method_handler(
                    servicer.TopicsPredict,
                    request_deserializer=common__service__pb2.TopicsRequest.FromString,
                    response_serializer=topic__types__pb2.TopicsPrediction.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'watson.runtime.nlp.v1.NlpService', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class NlpService(object):
    """Missing associated documentation comment in .proto file."""

    @staticmethod
    def ClassificationPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/ClassificationPredict',
            common__service__pb2.ClassificationRequest.SerializeToString,
            classification__types__pb2.ClassificationPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def SyntaxPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/SyntaxPredict',
            common__service__pb2.SyntaxRequest.SerializeToString,
            syntax__types__pb2.SyntaxPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def LangDetectPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/LangDetectPredict',
            common__service__pb2.LangDetectRequest.SerializeToString,
            lang__detect__types__pb2.LangDetectPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def EntityMentionsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/EntityMentionsPredict',
            common__service__pb2.EntityMentionsRequest.SerializeToString,
            entity__types__pb2.EntityMentionsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def NounPhrasesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/NounPhrasesPredict',
            common__service__pb2.NounPhrasesRequest.SerializeToString,
            nounphrases__types__pb2.NounPhrasesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def DetagPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/DetagPredict',
            common__service__pb2.DetagRequest.SerializeToString,
            syntax__types__pb2.DetagPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def RulesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/RulesPredict',
            common__service__pb2.RulesRequest.SerializeToString,
            rules__types__pb2.RulesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def CategoriesPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/CategoriesPredict',
            common__service__pb2.CategoriesRequest.SerializeToString,
            category__types__pb2.CategoriesPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def ConceptsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/ConceptsPredict',
            common__service__pb2.ConceptsRequest.SerializeToString,
            concept__types__pb2.ConceptsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def EmotionPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/EmotionPredict',
            common__service__pb2.EmotionRequest.SerializeToString,
            emotion__types__pb2.EmotionPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def KeywordsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/KeywordsPredict',
            common__service__pb2.KeywordsRequest.SerializeToString,
            keyword__types__pb2.KeywordsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def RelationsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/RelationsPredict',
            common__service__pb2.RelationsRequest.SerializeToString,
            relation__types__pb2.RelationsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def SentimentPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/SentimentPredict',
            common__service__pb2.SentimentRequest.SerializeToString,
            sentiment__types__pb2.SentimentPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def TargetsSentimentPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/TargetsSentimentPredict',
            common__service__pb2.TargetsSentimentRequest.SerializeToString,
            sentiment__types__pb2.TargetsSentimentPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def TopicsPredict(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/watson.runtime.nlp.v1.NlpService/TopicsPredict',
            common__service__pb2.TopicsRequest.SerializeToString,
            topic__types__pb2.TopicsPrediction.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
